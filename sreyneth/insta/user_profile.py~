import time
import io
import sys
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import TimeoutException
from selenium.common.exceptions import NoSuchElementException
from selenium.webdriver.common.keys import Keys
from selenium import selenium
import selenium 
import re
from selenium.webdriver.support.ui import Select
import urllib
import json
import csv
reload(sys)
sys.setdefaultencoding("UTF8")
#browser=webdriver.Firefox()
profile_url=' '


# path_to_chromedriver = '/Users/djisse/Documents/cheerio/chromedriver' # change path as needed
# browser = webdriver.Chrome(executable_path = path_to_chromedriver)
browser = webdriver.Firefox()

def scroll(url):
	try:
	    browser.wait = WebDriverWait(browser, 5)
	    browser.get(url)
	    browser.wait = WebDriverWait(browser, 5)
	    box = browser.wait.until(EC.presence_of_element_located((By.ID, "doc")))

	    for i in range(1,10):
	    	print "scrolling"
	    	browser.execute_script("window.scrollTo(0, document.body.scrollHeight);")
	    	time.sleep(2)
	    print 'scrolling finish'
	    return 1
	except NoSuchElementException,e:
		print 'Error in scrolling of '+url+' :'
		print(traceback.format_exc())
	except TimeoutException,e:
		print 'Sroll: Time out for '+url+' :'

def getlink():
		browser.get("https://www.instagram.com/sephora/")
		browser.wait = WebDriverWait(browser, 30)
		url = (browser.current_url)
		scroll(url)
		fs = io.open('link.csv', 'a', encoding='utf8')
		try:
			username=browser.find_element_by_css_selector('div._8mm5v > h1').get_attribute('textContent')
			print username
		except NoSuchElementException:
			username = "none"
		try:
			post_nb = browser.find_element_by_css_selector('li:nth-child(1) > span > span._e8fkl').get_attribute('textContent')
			print "Post number: " +post_nb
		except NoSuchElementException:
			post_nb = "0"
		try:
			following_nb = browser.find_element_by_css_selector('li:nth-child(3) > span > span._bgvpv').get_attribute('textContent')
			print "following number: " +following_nb
		except NoSuchElementException:
			following_nb = "0"
		try:
			follower_nb = browser.find_element_by_css_selector('li:nth-child(2) > span > span._pr3wx').get_attribute('textContent')
			print "follower number: " +follower_nb
		except NoSuchElementException:
			follower_nb = "0"
		try:
			profile_text = browser.find_element_by_css_selector('div._de9bg > div._bugdy').get_attribute('textContent')
			print profile_text
		except NoSuchElementException:
			profile_text = "none"
		# try:
		# 	readmore=browser.find_element_by_css_selector("article > div > div._pupj3 > a")
		# 	readmore.click()
		# 	time.sleep(4)
		# except NoSuchElementException:
		# 	print "not found readmore"
		try:
			getpost=browser.find_elements_by_css_selector(" div > div._nljxa > div> a")
			print len(getpost)
			for i in getpost:
				getlink=i.get_attribute("href")
				print getlink
				link = io.open('user_profile.csv', 'a', encoding='utf8')
				link.write(getlink+"\n")
		except NoSuchElementException:
			print "don't have post"
		# try:
		# 	popup=browser.find_element_by_css_selector('div._nljxa > div:nth-child(1) > a:nth-child(1) > div > div._ovg3g')
		# 	popup.click()
		# except NoSuchElementException:
		# 	popup = "none"

getlink()
browser.quit()
	
